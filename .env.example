# Model Serving Configuration
# Copy this file to .env and adjust values as needed

# Main llama-swap API port (clients connect here)
LLAMA_SWAP_PORT=5847

# Base port for llama-server instances (each model gets PORT + offset)
LLAMA_SERVER_BASE_PORT=5850

# Model idle timeout in seconds (30 min = 1800)
MODEL_TTL=1800

# Memory pressure threshold (percentage) for auto-unload
MEMORY_PRESSURE_THRESHOLD=75

# Pressure check interval in seconds
PRESSURE_CHECK_INTERVAL=30

# LM Studio models directory
MODELS_DIR=/Users/au/.cache/lm-studio/models

# Ollama-LM Studio bridge script path
BRIDGE_SCRIPT=/Users/au/src/lm-studio-ollama-bridge/lm-studio-ollama-bridge

# Bridge sync interval in seconds (1 hour = 3600)
BRIDGE_SYNC_INTERVAL=3600
